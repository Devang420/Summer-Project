{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eccaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lbfgs(f, grad_f, x0, m=10, tol=1e-5, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Limited-memory BFGS (L-BFGS) algorithm implementing two-loop recursion\n",
    "    based on Nocedal & Wright pseudocode.\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    k = 0  # iteration counter\n",
    "\n",
    "    s_list = []   \n",
    "    y_list = []   \n",
    "    rho_list = [] \n",
    "\n",
    "    g = grad_f(x)\n",
    "    BOUND = 0  # number of updates used\n",
    "\n",
    "    while np.linalg.norm(g) > tol and k < max_iter:\n",
    "        q = g.copy()\n",
    "        alpha = []\n",
    "\n",
    "        if k < m:\n",
    "            INCR = 0\n",
    "            BOUND = k\n",
    "        else:\n",
    "            INCR = k - m\n",
    "            BOUND = m\n",
    "\n",
    "        for i in range(BOUND - 1, -1, -1):\n",
    "            j = i + INCR\n",
    "            if j >= len(s_list):  # safety check\n",
    "                continue\n",
    "            s = s_list[j]\n",
    "            y = y_list[j]\n",
    "            rho = rho_list[j]\n",
    "            alpha_i = rho * np.dot(s, q)\n",
    "            alpha.append(alpha_i)\n",
    "            q = q - alpha_i * y\n",
    "\n",
    "        alpha = alpha[::-1]  # to use in forward loop later\n",
    "\n",
    "        if k > 0:\n",
    "            y_last = y_list[-1]\n",
    "            s_last = s_list[-1]\n",
    "            gamma = np.dot(s_last, y_last) / np.dot(y_last, y_last)\n",
    "        else:\n",
    "            gamma = 1.0\n",
    "        r = gamma * q\n",
    "\n",
    "        for i in range(0, BOUND):\n",
    "            j = i + INCR\n",
    "            if j >= len(s_list):  # safety check\n",
    "                continue\n",
    "            s = s_list[j]\n",
    "            y = y_list[j]\n",
    "            rho = rho_list[j]\n",
    "            beta = rho * np.dot(y, r)\n",
    "            r = r + s * (alpha[i] - beta)\n",
    "\n",
    "        #search direction and backtracking line search\n",
    "        p = -r\n",
    "        t = 1.0\n",
    "        while f(x + t * p) > f(x) + 1e-4 * t * np.dot(g, p):\n",
    "            t *= 0.5\n",
    "            if t < 1e-10:\n",
    "                break\n",
    "\n",
    "        #position and gradient update\n",
    "        x_new = x + t * p\n",
    "        g_new = grad_f(x_new)\n",
    "        s_k = x_new - x\n",
    "        y_k = g_new - g\n",
    "\n",
    "        #store s_k, y_k, and Ï_k if curvature condition satisfied\n",
    "        if np.dot(s_k, y_k) > 1e-10:\n",
    "            s_list.append(s_k)\n",
    "            y_list.append(y_k)\n",
    "            rho_list.append(1.0 / np.dot(y_k, s_k))\n",
    "\n",
    "            #maintaining memory size\n",
    "            if len(s_list) > m:\n",
    "                s_list.pop(0)\n",
    "                y_list.pop(0)\n",
    "                rho_list.pop(0)\n",
    "\n",
    "        x = x_new\n",
    "        g = g_new\n",
    "        k += 1\n",
    "\n",
    "        print(f\"Iter {k:2d} | f(x) = {f(x):.6f} | ||grad|| = {np.linalg.norm(g):.2e}\")\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7949c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a2d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=(x-3)**2 + (y-2)**2\n",
    "def f8(v):\n",
    "    x, y = v\n",
    "    return (x - 3)**2 + (y - 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=5x**2 + y**2\n",
    "def f5(v):\n",
    "    x, y = v\n",
    "    return 5 * x**2 + y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195152f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=sin(x)+y**2\n",
    "def f10(v):\n",
    "    x, y = v\n",
    "    return np.sin(x) + y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "deb90241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a noisy function\n",
    "K = 10\n",
    "alpha = 0\n",
    "np.random.seed(27)\n",
    "phi = 1 * np.pi * np.random.rand(K, K)  # fixed phases\n",
    "\n",
    "# Function f(v) = sin(x) + y^2 + noise\n",
    "#changed to f(v) = x^2 + y^2 + noise\n",
    "def f_structured(v):\n",
    "    x, y = v\n",
    "    f_val = x**2 + y**2\n",
    "    for k1 in range(K):\n",
    "        for k2 in range(K):\n",
    "            amp = 1.0 / (1 + k1**2 + k2**2)**(alpha / 2)\n",
    "            f_val += 0.5*(amp * np.cos(k1 * x + k2 * y + phi[k1, k2]))\n",
    "    return f_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4998688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function grad that calculates gradient numerically \n",
    "def grad_numerical(func, v, h=1e-7):\n",
    "    grad = np.zeros_like(v)\n",
    "    for i in range(len(v)):\n",
    "        v_plus = np.copy(v)\n",
    "        v_minus = np.copy(v)\n",
    "        v_plus[i] += h\n",
    "        v_minus[i] -= h\n",
    "        grad[i] = (func(v_plus) - func(v_minus)) / (2 * h)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05e6ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  1 | f(x) = -0.989393 | ||grad|| = 1.45e-01\n",
      "Iter  2 | f(x) = -0.997326 | ||grad|| = 7.31e-02\n",
      "Iter  3 | f(x) = -1.000000 | ||grad|| = 3.91e-04\n",
      "Iter  4 | f(x) = -1.000000 | ||grad|| = 3.47e-07\n",
      "\n",
      "Minimum found at: [ 4.71238933e+00 -2.23647882e-10]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([5, 16.0])\n",
    "xmin = lbfgs(f10, lambda x: grad_numerical(f10, x), x0)\n",
    "print(\"\\nMinimum found at:\", xmin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
